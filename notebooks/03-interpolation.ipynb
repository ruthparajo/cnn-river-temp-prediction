{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16955,
     "status": "ok",
     "timestamp": 1727963151889,
     "user": {
      "displayName": "Ruth Parajó Ferrer",
      "userId": "07031545869212809064"
     },
     "user_tz": -120
    },
    "id": "knivKlf6mv1P",
    "outputId": "fd1d01a1-7170-430c-f009-17b041ef18aa"
   },
   "outputs": [],
   "source": [
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 6746,
     "status": "ok",
     "timestamp": 1727963158628,
     "user": {
      "displayName": "Ruth Parajó Ferrer",
      "userId": "07031545869212809064"
     },
     "user_tz": -120
    },
    "id": "tc9wETqQYVRV",
    "outputId": "a56342b4-d718-4420-a519-d941f007ebbc"
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from rasterio.windows import Window\n",
    "import fiona\n",
    "from shapely.geometry import shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dGjkDYZ_Y5xM"
   },
   "source": [
    "### Project leboiron linestrings into points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from rasterio.features import shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import fiona\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import shape\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.ops import unary_union\n",
    "\n",
    "rivers = {}\n",
    "\n",
    "output_directory = '../data/external/shp/clipped_rivers_grid_cells_ogr'\n",
    "a=0\n",
    "for i,riv in enumerate(os.listdir(output_directory)):\n",
    "    # Check if the file is a shapefile\n",
    "    try:\n",
    "        if riv.endswith('.shp'):\n",
    "            a+=1\n",
    "            print(f\"Processing file: {riv}\")\n",
    "            river = gpd.read_file(os.path.join(output_directory, riv))\n",
    "            combined_river = unary_union(river.geometry)\n",
    "            \n",
    "            total_length = combined_river.length  # Longitud total en metros\n",
    "\n",
    "            # Calcular el área del bounding box de la geometría combinada\n",
    "            bounding_box = river.total_bounds  # [minx, miny, maxx, maxy]\n",
    "            width = bounding_box[2] - bounding_box[0]\n",
    "            height = bounding_box[3] - bounding_box[1]\n",
    "            area = width * height  # Área en metros \n",
    "\n",
    "            bounding_box_diagonal = ((bounding_box[2] - bounding_box[0])**2 + (bounding_box[3] - bounding_box[1])**2)**0.5\n",
    "\n",
    "            length_percentage = (total_length / bounding_box_diagonal) * 100  # Comparación en función de la diagonal\n",
    "            \n",
    "            # Definir umbrales\n",
    "            min_area_threshold = 225_000  # Área mínima en m² (0.225 km²)\n",
    "            min_length_threshold = 300  # Longitud mínima en metros\n",
    "\n",
    "            # Plot the GeoDataFrame\n",
    "            #river = river.to_crs(\"EPSG:4326\")\n",
    "            print('Tinc area i longitud', area, total_length)\n",
    "            #rivers[f'cell_{i}'] = river\n",
    "            if area > min_area_threshold and total_length > min_length_threshold and length_percentage > 50:\n",
    "                river.plot()\n",
    "                plt.title(f\"River data from: {riv}\")\n",
    "                plt.show()\n",
    "                river = river.to_crs(\"EPSG:2056\")\n",
    "                rivers[f'cell_{i}'] = river\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file: {riv}\",e)\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Air interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rivers['cell_4']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_stations_total_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1727963865870,
     "user": {
      "displayName": "Ruth Parajó Ferrer",
      "userId": "07031545869212809064"
     },
     "user_tz": -120
    },
    "id": "9GSadU1eKClO"
   },
   "outputs": [],
   "source": [
    "start_date = '2013-03-01'\n",
    "end_date = '2019-12-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_path = '../data/preprocessed/wt_interpolated'\n",
    "\n",
    "os.makedirs(raw_data_path, exist_ok=True)\n",
    "clear_directory(raw_data_path)\n",
    "\n",
    "for r in rivers.keys():\n",
    "  dest_dir = os.path.join(raw_data_path, r)\n",
    "  os.makedirs(dest_dir, exist_ok=True)\n",
    "  clear_directory(dest_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "\n",
    "def get_closest_grid_cell(x, y, x_range, y_range):\n",
    "    x_idx = np.argmin(np.abs(x_range - x))\n",
    "    y_idx = np.argmin(np.abs(y_range - y))\n",
    "    return x_idx, y_idx\n",
    "\n",
    "def generate_raster(df, shp, river, folder_path,var,date=None):\n",
    "\n",
    "    # Extract the coordinate columns (Coord X, Coord Y)\n",
    "    x_coords = df['Coord X'].values\n",
    "    y_coords = df['Coord Y'].values\n",
    "    \n",
    "    # Define bounds and resolution for the grid\n",
    "    bounds = shp.total_bounds\n",
    "    resolution = 30\n",
    "    x_min, y_min, x_max, y_max = bounds\n",
    "    x_range = np.arange(x_min, x_max, resolution)\n",
    "    y_range = np.arange(y_min, y_max, resolution)\n",
    "    \n",
    "    # Precompute the grid cell indices for all coordinates\n",
    "    grid_indices = [get_closest_grid_cell(x, y, x_range, y_range) for x, y in zip(x_coords, y_coords)]\n",
    "    \n",
    "    # Define the transformation for the raster grid\n",
    "    transform = from_origin(x_min, y_max, resolution, resolution)\n",
    "    \n",
    "    # Loop through each temperature column (each date)\n",
    "    #for col in df.columns[2:]:  # Assuming temperature columns start from the 4th column onward\n",
    "\n",
    "    #var = df[col].values  # Extract the variable data for the current date\n",
    "    \n",
    "    var_values = df[var].values\n",
    "\n",
    "    # Initialize an array to store temperature values for the current day\n",
    "\n",
    "    raster_array = np.ones((len(y_range), len(x_range)))\n",
    "\n",
    "    # Assign temperature values to the grid cells based on precomputed indices\n",
    "    for i, (x_idx, y_idx) in enumerate(grid_indices):\n",
    "        temp = var_values[i]\n",
    "        raster_array[y_idx, x_idx] = temp\n",
    "        #print('li poso', temp)\n",
    "    filename = f'{folder_path}/{date}.tif' if date != None else f'{folder_path}/{river}.tif'\n",
    "    save_raster(np.flipud(raster_array),filename, shp)\n",
    "    print('Saved at', filename)\n",
    "\n",
    "    vmin = np.min(raster_array)\n",
    "    vmax = np.max(raster_array)\n",
    "    if vmin == vmax:\n",
    "        vmin -= 0.01  # Slight adjustment to avoid identical vmin and vmax\n",
    "    try:\n",
    "        plt.imshow(raster_array, cmap='inferno', origin='lower')#, extent=[x_min, x_max, y_min, y_max],norm=LogNorm())\n",
    "        plt.colorbar(label='1')\n",
    "        plt.title(f'{var} Heatmap for {river}')\n",
    "        plt.show()\n",
    "\n",
    "    except ValueError as e:\n",
    "        try:\n",
    "            plt.imshow(raster_array, cmap='inferno', origin='lower', extent=[x_min, x_max, y_min, y_max],norm=LogNorm(vmin = vmin, vmax = vmax))\n",
    "            plt.colorbar(label='2')\n",
    "            plt.title(f'{var} Heatmap for {river}')\n",
    "            plt.show()\n",
    "        except:\n",
    "            plt.imshow(raster_array, cmap='inferno', origin='lower', extent=[x_min, x_max, y_min, y_max])\n",
    "            plt.colorbar(label='3')\n",
    "            plt.title(f'{var} Heatmap for {river}')\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 912
    },
    "executionInfo": {
     "elapsed": 2524,
     "status": "ok",
     "timestamp": 1727963161147,
     "user": {
      "displayName": "Ruth Parajó Ferrer",
      "userId": "07031545869212809064"
     },
     "user_tz": -120
    },
    "id": "tLm6kZx5YXNR",
    "outputId": "fe08049b-a32c-4f64-88fd-b43946b514cf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/external/airtemp_files'\n",
    "for k,river in rivers.items():\n",
    "    folder_path = f'../data/preprocessed/air_interpolated/{k}'\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    clear_directory(folder_path)\n",
    "    print('fent',k)\n",
    "    x_coords, y_coords, z_coords = project_linestrings_to_points(river)\n",
    "    #print(x_coords,y_coords)\n",
    "    \n",
    "    if z_coords == []:\n",
    "        dir_altitudes = '../data/external/altitudes'\n",
    "        with rasterio.open('../../../../../data/simon.walther/swissAltitude/swissAltitude.vrt') as src:\n",
    "            for i in range(len(x_coords)):\n",
    "                lon, lat = x_coords[i], y_coords[i]\n",
    "                row, col = src.index(lon, lat)\n",
    "                window = Window(col_off=col, row_off=row, width=1, height=1)\n",
    "                pixel_value = src.read(1, window=window)\n",
    "                z_coords.append(pixel_value[0][0])\n",
    "                \n",
    "    grid_x, grid_y = np.mgrid[min(x_coords):max(x_coords):256j, min(y_coords):max(y_coords):256j]\n",
    "\n",
    "    # Interpolación de los valores de altitud en la cuadrícula\n",
    "    grid_z = griddata((x_coords, y_coords), z_coords, (grid_x, grid_y), method='cubic')\n",
    "    altitude_path = f'../data/preprocessed/altitude/{k}.tif'\n",
    "    save_raster(grid_z, altitude_path, river)\n",
    "    print('Saved', altitude_path)\n",
    "        \n",
    "    projection_coordenates = pd.DataFrame(data={'Coord X': x_coords,'Coord Y': y_coords,'Altitude': z_coords})\n",
    "    \n",
    "    air_stations_total_data = pd.read_csv(os.path.join(DATA_PATH, '30MinFreq_air_boiron_and_swissmeteo_data.csv'),index_col=0)\n",
    "    air_stations_total_metadata = pd.read_csv(os.path.join(DATA_PATH, 'air_boiron_and_swissmeteo_metadata.csv'),index_col=0)\n",
    "    \n",
    "    # Filter the data to the selected time period\n",
    "    air_stations_filt = air_stations_total_data.loc[start_date:end_date]\n",
    "    air_stations_filt.index = pd.to_datetime(air_stations_filt.index)\n",
    "    air_stations_monthly_mean = air_stations_filt.resample('M').mean()\n",
    "\n",
    "    # Interpolate the data\n",
    "    LR = 5.5\n",
    "    air_interpolated = pd.DataFrame(columns=projection_coordenates.index)\n",
    "\n",
    "    for ri,r in air_stations_monthly_mean.iterrows():\n",
    "        temp = pd.concat([pd.DataFrame(r.values, index=r.index, columns=['temp',]), air_stations_total_metadata], axis=1)\n",
    "        temp.dropna(inplace=True)\n",
    "\n",
    "        temp['temp'] += LR * temp['Altitude'] / 1000\n",
    "\n",
    "        if len(temp) == 0:\n",
    "            a = np.empty(projection_coordenates.shape[0])\n",
    "            a[:] = np.nan\n",
    "            air_interpolated.loc[ri] = a\n",
    "        else:\n",
    "            x = temp['Coord X']\n",
    "            y = temp['Coord Y']\n",
    "            z = temp['temp']\n",
    "\n",
    "            xi = projection_coordenates['Coord X']\n",
    "            yi = projection_coordenates['Coord Y']\n",
    "\n",
    "            temp_interpolated = simple_idw(x, y, z, xi, yi, beta=2)\n",
    "            temp_interpolated -= LR * projection_coordenates['Altitude']  / 1000\n",
    "\n",
    "            air_interpolated.loc[ri] = temp_interpolated\n",
    "            \n",
    "            df_air = pd.DataFrame(np.transpose(temp_interpolated))\n",
    "            var = 'water_temp'\n",
    "            df_air.columns = {var}\n",
    "            #print('aaaaa')\n",
    "            #print(df_air)\n",
    "            #print(df_air.columns)\n",
    "            df = pd.concat([projection_coordenates,df_air],axis =1,ignore_index = False)\n",
    "            #print(df)\n",
    "            \n",
    "            generate_raster(df, river, k, folder_path, var, ri.strftime(\"%Y-%m\"))\n",
    "        \n",
    "    #air_interpolated.to_csv(os.path.join(raw_data_path,'air_interpolated_leboiron.csv'), header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_interpolated.to_csv(os.path.join(raw_data_path,'air_interpolated_leboiron.csv'), header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aRu62HzgZKol"
   },
   "source": [
    "#### Show and save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to map coordinates to the grid (pre-compute grid indices)\n",
    "def get_closest_grid_cell(x, y, x_range, y_range):\n",
    "    x_idx = np.argmin(np.abs(x_range - x))\n",
    "    y_idx = np.argmin(np.abs(y_range - y))\n",
    "    return x_idx, y_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 269,
     "status": "ok",
     "timestamp": 1727963878494,
     "user": {
      "displayName": "Ruth Parajó Ferrer",
      "userId": "07031545869212809064"
     },
     "user_tz": -120
    },
    "id": "-j_0b7WOaGig"
   },
   "outputs": [],
   "source": [
    "folder_path = '../data/raw/airtemp_interpolated'\n",
    "\n",
    "# List all files in the folder and delete them\n",
    "for file_name in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    try:\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1adYOTX8mihVdfCtVhSs26sqGvhHVBfrV"
    },
    "executionInfo": {
     "elapsed": 61416,
     "status": "ok",
     "timestamp": 1727964108736,
     "user": {
      "displayName": "Ruth Parajó Ferrer",
      "userId": "07031545869212809064"
     },
     "user_tz": -120
    },
    "id": "M5AWxEtbcFq4",
    "outputId": "429886ce-8016-436a-e090-4bead6737c60",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k,river in rivers.items():\n",
    "    \n",
    "    df = projection_coordenates.join(np.transpose(air_interpolated))\n",
    "\n",
    "    # Extract the coordinate columns (Coord X, Coord Y)\n",
    "    x_coords = df['Coord X'].values\n",
    "    y_coords = df['Coord Y'].values\n",
    "\n",
    "    # Define bounds and resolution for the grid\n",
    "    bounds = river.total_bounds\n",
    "    resolution = 30\n",
    "    x_min, y_min, x_max, y_max = bounds\n",
    "    x_range = np.arange(x_min, x_max, resolution)\n",
    "    y_range = np.arange(y_min, y_max, resolution)\n",
    "\n",
    "    # Precompute the grid cell indices for all coordinates\n",
    "    grid_indices = [get_closest_grid_cell(x, y, x_range, y_range) for x, y in zip(x_coords, y_coords)]\n",
    "\n",
    "    # Define the transformation for the raster grid\n",
    "    transform = from_origin(x_min, y_max, resolution, resolution)\n",
    "\n",
    "    # Loop through each temperature column (each date)\n",
    "    for col in df.columns[3:]:  # Assuming temperature columns start from the 4th column onward\n",
    "        temperature = df[col].values  # Extract the temperature data for the current date\n",
    "\n",
    "        # Initialize an array to store temperature values for the current day\n",
    "        raster_array = np.zeros((len(y_range), len(x_range)))\n",
    "\n",
    "        # Assign temperature values to the grid cells based on precomputed indices\n",
    "        for i, (x_idx, y_idx) in enumerate(grid_indices):\n",
    "            temp = temperature[i]\n",
    "            raster_array[y_idx, x_idx] = temp\n",
    "\n",
    "        save_raster(np.flipud(raster_array),f'{folder_path}/airtemp_{col.strftime(\"%Y-%m\")}.tif',river)\n",
    "\n",
    "\n",
    "        # Optional: Visualize the temperature grid for each day\n",
    "        plt.imshow(raster_array, cmap='hot', origin='lower', extent=[x_min, x_max, y_min, y_max])\n",
    "        plt.colorbar(label='Temperature')\n",
    "        plt.title(f'Temperature Heatmap for {col}')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-fpNkBGOdtWU"
   },
   "source": [
    "## Water interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y_s3PUgFf1ss"
   },
   "source": [
    "#### Load data and filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "executionInfo": {
     "elapsed": 2852,
     "status": "ok",
     "timestamp": 1727964111580,
     "user": {
      "displayName": "Ruth Parajó Ferrer",
      "userId": "07031545869212809064"
     },
     "user_tz": -120
    },
    "id": "LPfNU04xg1WA",
    "outputId": "30a82acc-5d3c-449f-f7ed-4c746ca7bb62"
   },
   "outputs": [],
   "source": [
    "water_stations = pd.read_csv('../data/external/watertemp files/water_boiron_2011_2023.csv')\n",
    "water_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1727964111580,
     "user": {
      "displayName": "Ruth Parajó Ferrer",
      "userId": "07031545869212809064"
     },
     "user_tz": -120
    },
    "id": "47UvCRrui5yA"
   },
   "outputs": [],
   "source": [
    "start_date = pd.to_datetime('01-03-2013', dayfirst=True)  # Define start date in the correct format\n",
    "end_date = pd.to_datetime('25-07-2023', dayfirst=True)    # You can set end date as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1694,
     "status": "ok",
     "timestamp": 1727964113268,
     "user": {
      "displayName": "Ruth Parajó Ferrer",
      "userId": "07031545869212809064"
     },
     "user_tz": -120
    },
    "id": "-JZzlcCCdwrp",
    "outputId": "2a8a9810-a3f2-4ba7-c207-1ec484a20651"
   },
   "outputs": [],
   "source": [
    "# Asegúrate de que la columna de fechas esté en formato datetime\n",
    "water_stations['Date et heure'] = pd.to_datetime(water_stations['Date et heure'],format='%d.%m.%Y %H:%M:%S', dayfirst=True)\n",
    "\n",
    "# Establecer la columna 'Date et heure' como índice\n",
    "water_stations.set_index('Date et heure', inplace=True)\n",
    "\n",
    "# Filtrar por el rango de fechas deseado\n",
    "water_stations_filt = water_stations.loc[start_date:end_date]\n",
    "\n",
    "# Calcular la media mensual\n",
    "water_stations_monthly_mean = water_stations_filt.resample('M').mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b86jSgREl0M6"
   },
   "source": [
    "Load water stations metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 638
    },
    "executionInfo": {
     "elapsed": 1049,
     "status": "ok",
     "timestamp": 1727964114313,
     "user": {
      "displayName": "Ruth Parajó Ferrer",
      "userId": "07031545869212809064"
     },
     "user_tz": -120
    },
    "id": "AKNteBkEjgui",
    "outputId": "dd75b148-0db8-4bb7-a292-97ede6c73379"
   },
   "outputs": [],
   "source": [
    "water_stations_total_metadata = pd.read_csv('../data/external/watertemp files/water_stations_with_Qratio.csv')\n",
    "water_stations_total_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q2wfrBHLmYUm"
   },
   "source": [
    "#### Interpolation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1727964114313,
     "user": {
      "displayName": "Ruth Parajó Ferrer",
      "userId": "07031545869212809064"
     },
     "user_tz": -120
    },
    "id": "lpKfxmOQAWsD",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "d3ae481f-c5ed-4646-d072-84a360fe1632"
   },
   "outputs": [],
   "source": [
    "water_stations_total_metadata.index = water_stations_total_metadata['CODE_MdlR']\n",
    "water_stations_total_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 4384,
     "status": "ok",
     "timestamp": 1727964118692,
     "user": {
      "displayName": "Ruth Parajó Ferrer",
      "userId": "07031545869212809064"
     },
     "user_tz": -120
    },
    "id": "w_-CU0b8mZyf",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "cc746e3b-6cca-40c5-e820-f7f6deeba31b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "LR = 5.5\n",
    "water_interpolated = pd.DataFrame(columns=projection_coordenates.index)\n",
    "\n",
    "for ri,r in water_stations_monthly_mean.iterrows():\n",
    "    temp = pd.concat([pd.DataFrame(r.values, index=r.index, columns=['temp',]),water_stations_total_metadata], axis=1)\n",
    "    temp.dropna(inplace=True)\n",
    "\n",
    "    temp['temp'] += LR * temp['Altitude'] / 1000\n",
    "    if len(temp) == 0:\n",
    "        a = np.empty(projection_coordenates.shape[0])\n",
    "        a[:] = np.nan\n",
    "        water_interpolated.loc[ri] = a\n",
    "    else:\n",
    "        x = temp['Coord X']\n",
    "        y = temp['Coord Y']\n",
    "        z = temp['temp']\n",
    "\n",
    "        xi = projection_coordenates['Coord X']\n",
    "        yi = projection_coordenates['Coord Y']\n",
    "\n",
    "        temp_interpolated = simple_idw(x, y, z, xi, yi, beta=2)\n",
    "        temp_interpolated -= LR * projection_coordenates['Altitude']  / 1000\n",
    "\n",
    "        water_interpolated.loc[ri] = temp_interpolated\n",
    "        print(temp_interpolated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3363,
     "status": "ok",
     "timestamp": 1727964122048,
     "user": {
      "displayName": "Ruth Parajó Ferrer",
      "userId": "07031545869212809064"
     },
     "user_tz": -120
    },
    "id": "aEwTddB4mgxO"
   },
   "outputs": [],
   "source": [
    "water_interpolated.to_csv('../data/external/water_interpolated_leboiron.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1727964122050,
     "user": {
      "displayName": "Ruth Parajó Ferrer",
      "userId": "07031545869212809064"
     },
     "user_tz": -120
    },
    "id": "wWIhHaNnmo26"
   },
   "outputs": [],
   "source": [
    "df = projection_coordenates.join(np.transpose(water_interpolated))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t4F5W0RXnbSd"
   },
   "source": [
    "#### Show and save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 313,
     "status": "ok",
     "timestamp": 1727964122350,
     "user": {
      "displayName": "Ruth Parajó Ferrer",
      "userId": "07031545869212809064"
     },
     "user_tz": -120
    },
    "id": "z7TaHkjWnZ8S"
   },
   "outputs": [],
   "source": [
    "folder_path = '../data/raw/wt_interpolated'\n",
    "\n",
    "# List all files in the folder and delete them\n",
    "for file_name in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    try:\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1GTzyZdftz9wmmOIb7zA8OaSwnE585q9r"
    },
    "executionInfo": {
     "elapsed": 64477,
     "status": "ok",
     "timestamp": 1727964186821,
     "user": {
      "displayName": "Ruth Parajó Ferrer",
      "userId": "07031545869212809064"
     },
     "user_tz": -120
    },
    "id": "nYUbRgJxnjd-",
    "outputId": "00e0c1b1-9c4b-4b17-c8ad-a7258049956d"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract the coordinate columns (Coord X, Coord Y)\n",
    "x_coords = df['Coord X'].values\n",
    "y_coords = df['Coord Y'].values\n",
    "\n",
    "# Define bounds and resolution for the grid\n",
    "bounds = leboiron.total_bounds\n",
    "resolution = 30\n",
    "x_min, y_min, x_max, y_max = bounds\n",
    "x_range = np.arange(x_min, x_max, resolution)\n",
    "y_range = np.arange(y_min, y_max, resolution)\n",
    "\n",
    "# Function to map coordinates to the grid (pre-compute grid indices)\n",
    "def get_closest_grid_cell(x, y, x_range, y_range):\n",
    "    x_idx = np.argmin(np.abs(x_range - x))\n",
    "    y_idx = np.argmin(np.abs(y_range - y))\n",
    "    return x_idx, y_idx\n",
    "\n",
    "# Precompute the grid cell indices for all coordinates\n",
    "grid_indices = [get_closest_grid_cell(x, y, x_range, y_range) for x, y in zip(x_coords, y_coords)]\n",
    "\n",
    "# Define the transformation for the raster grid\n",
    "transform = from_origin(x_min, y_max, resolution, resolution)\n",
    "\n",
    "# Loop through each temperature column (each date)\n",
    "for col in df.columns[3:]:  # Assuming temperature columns start from the 4th column onward\n",
    "    temperature = df[col].values  # Extract the temperature data for the current date\n",
    "\n",
    "    # Initialize an array to store temperature values for the current day\n",
    "    raster_array = np.zeros((len(y_range), len(x_range)))\n",
    "\n",
    "    # Assign temperature values to the grid cells based on precomputed indices\n",
    "    for i, (x_idx, y_idx) in enumerate(grid_indices):\n",
    "        temp = temperature[i]\n",
    "        raster_array[y_idx, x_idx] = temp\n",
    "\n",
    "    save_raster(np.flipud(raster_array),f'{folder_path}/watertemp_{col.strftime(\"%Y-%m\")}.tif',leboiron)\n",
    "\n",
    "\n",
    "    # Optional: Visualize the temperature grid for each day\n",
    "    plt.imshow(raster_array, cmap='hot', origin='lower', extent=[x_min, x_max, y_min, y_max])\n",
    "    plt.colorbar(label='Temperature')\n",
    "    plt.title(f'Temperature Heatmap for {col}')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slope and discharge interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(rivers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../data/external/slope_discharge/Typisierung_LV95/typisierung.gpkg'\n",
    "gdf = gpd.read_file(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gdf = gdf.to_crs(\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gdf.crs)\n",
    "print(rivers['LaVenoge_shapefile'].crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rivers['Malbunbach'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Graficar el primer GeoDataFrame (gdf1) en azul\n",
    "gdf.plot(ax=ax, color='blue', edgecolor='black', label='GDF 1')\n",
    "\n",
    "# Graficar el segundo GeoDataFrame (gdf2) en rojo\n",
    "rivers['Malbunbach'].plot(ax=ax, color='red', edgecolor='black', label='GDF 2')\n",
    "\n",
    "# Agregar leyenda\n",
    "plt.legend()\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf[gdf.intersects(rivers['Malbunbach'].unary_union)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "\n",
    "def get_closest_grid_cell(x, y, x_range, y_range):\n",
    "    x_idx = np.argmin(np.abs(x_range - x))\n",
    "    y_idx = np.argmin(np.abs(y_range - y))\n",
    "    return x_idx, y_idx\n",
    "\n",
    "def generate_raster(df, shp, river, folder_path):\n",
    "    print('holaaa')\n",
    "\n",
    "    # Extract the coordinate columns (Coord X, Coord Y)\n",
    "    x_coords = df['Coord X'].values\n",
    "    y_coords = df['Coord Y'].values\n",
    "    \n",
    "    # Define bounds and resolution for the grid\n",
    "    bounds = shp.total_bounds\n",
    "    resolution = 30\n",
    "    x_min, y_min, x_max, y_max = bounds\n",
    "    x_range = np.arange(x_min, x_max, resolution)\n",
    "    y_range = np.arange(y_min, y_max, resolution)\n",
    "    \n",
    "    # Precompute the grid cell indices for all coordinates\n",
    "    grid_indices = [get_closest_grid_cell(x, y, x_range, y_range) for x, y in zip(x_coords, y_coords)]\n",
    "    \n",
    "    # Define the transformation for the raster grid\n",
    "    transform = from_origin(x_min, y_max, resolution, resolution)\n",
    "    \n",
    "    # Loop through each temperature column (each date)\n",
    "    for col in df.columns[2:]:  # Assuming temperature columns start from the 4th column onward\n",
    "        print(col)\n",
    "        var = df[col].values  # Extract the variable data for the current date\n",
    "    \n",
    "        # Initialize an array to store temperature values for the current day\n",
    "        raster_array = np.zeros((len(y_range), len(x_range)))\n",
    "    \n",
    "        # Assign temperature values to the grid cells based on precomputed indices\n",
    "        for i, (x_idx, y_idx) in enumerate(grid_indices):\n",
    "            temp = var[i]\n",
    "            raster_array[y_idx, x_idx] = temp\n",
    "    \n",
    "        save_raster(np.flipud(raster_array),f'{folder_path}/discharge_{river}.tif', shp)\n",
    "    \n",
    "        vmin = np.min(raster_array)\n",
    "        vmax = np.max(raster_array)\n",
    "        if vmin == vmax:\n",
    "            vmin -= 0.01  # Slight adjustment to avoid identical vmin and vmax\n",
    "        print('helou',vmin, vmax)\n",
    "        try:\n",
    "            plt.imshow(raster_array, cmap='inferno', origin='lower', extent=[x_min, x_max, y_min, y_max],norm=LogNorm())\n",
    "            plt.colorbar(label='1')\n",
    "            plt.title(f'{col} Heatmap for {river}')\n",
    "            plt.show()\n",
    "\n",
    "        except ValueError as e:\n",
    "            try:\n",
    "                plt.imshow(raster_array, cmap='inferno', origin='lower', extent=[x_min, x_max, y_min, y_max],norm=LogNorm(vmin = vmin, vmax = vmax))\n",
    "                plt.colorbar(label='2')\n",
    "                plt.title(f'{col} Heatmap for {river}')\n",
    "                plt.show()\n",
    "            except:\n",
    "                plt.imshow(raster_array, cmap='inferno', origin='lower', extent=[x_min, x_max, y_min, y_max])\n",
    "                plt.colorbar(label='3')\n",
    "                plt.title(f'{col} Heatmap for {river}')\n",
    "                plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.interpolate import griddata\n",
    "PATH_DATA = '../data/external/'\n",
    "for k,river in rivers.items():\n",
    "\n",
    "    print('fent',k)\n",
    "    x_coords, y_coords, z_coords = project_linestrings_to_points(river)\n",
    "    \n",
    "    if z_coords == []:\n",
    "        dir_altitudes = '../data/external/altitudes'\n",
    "        with rasterio.open('../../../../../data/simon.walther/swissAltitude/swissAltitude.vrt') as src:\n",
    "            for i in range(len(x_coords)):\n",
    "                lon, lat = x_coords[i], y_coords[i]\n",
    "                row, col = src.index(lon, lat)\n",
    "                window = Window(col_off=col, row_off=row, width=1, height=1)\n",
    "                pixel_value = src.read(1, window=window)\n",
    "                z_coords.append(pixel_value[0][0])\n",
    "    \n",
    "    # Crear una cuadrícula (grid) de puntos donde interpolar los valores\n",
    "    grid_x, grid_y = np.mgrid[min(x_coords):max(x_coords):256j, min(y_coords):max(y_coords):256j]\n",
    "\n",
    "    # Interpolación de los valores de altitud en la cuadrícula\n",
    "    grid_z = griddata((x_coords, y_coords), z_coords, (grid_x, grid_y), method='cubic')\n",
    "\n",
    "    # Visualizar la imagen resultante con matplotlib\n",
    "    plt.imshow(grid_z, extent=(min(x_coords), max(x_coords), min(y_coords), max(y_coords)), origin='lower', cmap='terrain')\n",
    "    plt.colorbar(label='Altitud')\n",
    "    plt.title('Altitud Interpolada')\n",
    "    plt.show()\n",
    "\n",
    "    projection_coordenates = pd.DataFrame(data={'Coord X': x_coords,'Coord Y': y_coords})#,'Altitude': z_coords})\n",
    "    print(projection_coordenates.shape)\n",
    "    print('done coordenates')\n",
    "    \n",
    "    gdf_filtered = gdf[gdf.intersects(river.unary_union)]\n",
    "    if not gdf_filtered.empty:\n",
    "        disch = []\n",
    "        slopes = []\n",
    "        x_coords_gdf = []\n",
    "        y_coords_gdf = []\n",
    "        z_coords_gdf = []\n",
    "        for i,row in gdf_filtered.iterrows():\n",
    "            geom = row.geometry\n",
    "            for linestring in geom.geoms:\n",
    "                for coord in linestring.coords:\n",
    "                    if k == 'Malbunbach':\n",
    "                        print('Coordenades:', coord[0], coord[1])\n",
    "                    x_coords_gdf.append(coord[0])\n",
    "                    y_coords_gdf.append(coord[1])\n",
    "                    if len(coord) == 3:\n",
    "                        z_coords_gdf.append(coord[2])\n",
    "                    disch.append(row.Discharge)\n",
    "                    slopes.append(row.Slope)\n",
    "    \n",
    "        \n",
    "        print(len(x_coords_gdf), len(y_coords_gdf),len(disch), len(slopes))           \n",
    "    \n",
    "        print('done gdf coordenates')\n",
    "        projection_coordenates_filtered = pd.DataFrame(data={'Discharge': disch,'Slope':slopes,'Coord X': x_coords_gdf,'Coord Y': y_coords_gdf})#,'Altitude': z_coords_gdf})\n",
    "        print(projection_coordenates_filtered.shape)\n",
    "        \n",
    "        # Interpolate the data\n",
    "        LR = 5.5\n",
    "        discharge_interpolated_df = pd.DataFrame(columns=projection_coordenates.index)\n",
    "        slope_interpolated_df = pd.DataFrame(columns=projection_coordenates.index)\n",
    "        \n",
    "    \n",
    "        temp = projection_coordenates_filtered.copy()\n",
    "        #temp.dropna(inplace=True)\n",
    "    \n",
    "        if len(temp) == 0:\n",
    "            a = np.empty(projection_coordenates.shape[0])\n",
    "            a[:] = np.nan\n",
    "            discharge_interpolated = a\n",
    "        else:\n",
    "            x = temp['Coord X']\n",
    "            y = temp['Coord Y']\n",
    "            z = temp['Discharge']\n",
    "            z_slope = temp['Slope']\n",
    "            \n",
    "    \n",
    "            xi = projection_coordenates['Coord X']\n",
    "            yi = projection_coordenates['Coord Y']\n",
    "            \n",
    "            #print('Soc discharge abans',z)\n",
    "            discharge_interpolated = simple_idw(x, y, z, xi, yi, beta=2)\n",
    "            #print('Soc discharge',discharge_interpolated)\n",
    "            #temp_interpolated -= LR * projection_coordenates['Altitude']  / 1000\n",
    "            discharge_interpolated_df.loc[0]=discharge_interpolated\n",
    "    \n",
    "            slope_interpolated = simple_idw(x, y, z_slope, xi, yi, beta=2)\n",
    "            slope_interpolated_df.loc[0]=slope_interpolated\n",
    "    \n",
    "        #discharge_interpolated_df.to_csv(os.path.join(PATH_DATA,f'discharge/discharge_interpolated_{k}.csv'), header=True)\n",
    "        #slope_interpolated_df.to_csv(os.path.join(PATH_DATA,f'slope/slope_interpolated_{k}.csv'), header=True)\n",
    "        \n",
    "        df_disch = np.transpose(discharge_interpolated_df)\n",
    "        df_disch.columns = {'Discharge'}\n",
    "        df = pd.concat([projection_coordenates,df_disch],axis =1,ignore_index = False)\n",
    "    \n",
    "        folder_path = f'../data/preprocessed/discharge/{k}'\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "        clear_directory(folder_path)\n",
    "        generate_raster(df, river, k, folder_path)\n",
    "        \n",
    "        df_slope = np.transpose(slope_interpolated_df)\n",
    "        df_slope.columns = {'Slope'}\n",
    "        df = pd.concat([projection_coordenates,df_slope],axis =1,ignore_index = False)\n",
    "        \n",
    "        folder_path = f'../data/preprocessed/slope/{k}'\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "        clear_directory(folder_path)\n",
    "        generate_raster(df, river, k, folder_path)\n",
    "        \n",
    "        \n",
    "        print('done',k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Water dataset interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_points = gpd.read_file('../data/external/wt_filtered/wt_filtered.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "LR = 5.5\n",
    "\n",
    "for k, river in rivers.items():\n",
    "    x_coords, y_coords, z_coords = project_linestrings_to_points(river)\n",
    "    \n",
    "    if z_coords == []:\n",
    "        dir_altitudes = '../data/external/altitudes'\n",
    "        with rasterio.open('../../../../../data/simon.walther/swissAltitude/swissAltitude.vrt') as src:\n",
    "            for i in range(len(x_coords)):\n",
    "                lon, lat = x_coords[i], y_coords[i]\n",
    "                row, col = src.index(lon, lat)\n",
    "                window = Window(col_off=col, row_off=row, width=1, height=1)\n",
    "                pixel_value = src.read(1, window=window)\n",
    "                z_coords.append(pixel_value[0][0])\n",
    "    \n",
    "    projection_coordenates = pd.DataFrame(data={'Coord X': x_coords,'Coord Y': y_coords,'Altitude': z_coords})\n",
    "    \n",
    "    water_coordinates = pd.DataFrame(data = {'Coord X': gdf_points['latitude'],'Coord Y': gdf_points['longitude'],'watertemp':gdf_points['waterTemperature']})\n",
    "    \n",
    "    water_interpolated = pd.DataFrame(columns=projection_coordenates.index)\n",
    "    temp = water_coordinates.copy()\n",
    "\n",
    "    if len(temp) == 0:\n",
    "        a = np.empty(projection_coordenates.shape[0])\n",
    "        a[:] = np.nan\n",
    "        discharge_interpolated = a\n",
    "    else:\n",
    "        x = temp['Coord X']\n",
    "        y = temp['Coord Y']\n",
    "        z = temp['watertemp']\n",
    "\n",
    "        xi = projection_coordenates['Coord X']\n",
    "        yi = projection_coordenates['Coord Y']\n",
    "        \n",
    "        #print('Soc discharge abans',z)\n",
    "        w_interpolated = simple_idw(x, y, z, xi, yi, beta=2)\n",
    "        #print('Soc discharge',discharge_interpolated)\n",
    "        #temp_interpolated -= LR * projection_coordenates['Altitude']  / 1000\n",
    "        water_interpolated.loc[0]=w_interpolated\n",
    "\n",
    "    df_disch = np.transpose(discharge_interpolated_df)\n",
    "    df_disch.columns = {'Discharge'}\n",
    "    df = pd.concat([projection_coordenates,df_disch],axis =1,ignore_index = False)\n",
    "\n",
    "    folder_path = f'../data/preprocessed/wt_interpolated/{k}'\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    clear_directory(folder_path)\n",
    "    generate_raster(df, river, k, folder_path)\n",
    "    print('Done',k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOA+Sa4lInXYF3F00JkOPHR",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
