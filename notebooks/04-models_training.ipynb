{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17776,
     "status": "ok",
     "timestamp": 1728026996326,
     "user": {
      "displayName": "Ruth Parajó Ferrer",
      "userId": "07031545869212809064"
     },
     "user_tz": -120
    },
    "id": "xJJ2jzpfkpt0",
    "outputId": "435323a9-257c-4d2a-9b4e-33146751fa24"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-31 14:53:55.733347: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-31 14:53:55.754480: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-31 14:53:55.760673: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-31 14:53:55.777458: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-31 14:53:56.997353: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from functions import *\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 760,
     "status": "ok",
     "timestamp": 1728026997084,
     "user": {
      "displayName": "Ruth Parajó Ferrer",
      "userId": "07031545869212809064"
     },
     "user_tz": -120
    },
    "id": "cdgXKy8WkrF0"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import geopandas as gpd\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ibqF7sdakyQ6"
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lst : (147, 256, 256, 3)\n",
      "wt : (147, 256, 256)\n",
      "ndvi : (147, 256, 256)\n",
      "slope : (147, 256, 256)\n",
      "discharge : (147, 256, 256)\n",
      "masked : (147, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "# Set variables\n",
    "source_folder = '../data/external/raster_masks'\n",
    "rivers = {}\n",
    "source_path = '../data/preprocessed/'\n",
    "data_paths = ['lst','wt','ndvi','slope', 'discharge','masked']#,'slope', 'discharge']#, 'ndvi', 'wt', 'masked','discharge', 'slope']#, 'wt_interpolated']\n",
    "dir_paths = [os.path.join(source_path,p) for p in data_paths]\n",
    "all_dir_paths = {k:[] for k in data_paths}    \n",
    "total_data = {}\n",
    "total_times = {}\n",
    "complete_rivers = []\n",
    "filter_river = None\n",
    "W=256\n",
    "\n",
    "# Load rivers\n",
    "for subdir, dirs, files in os.walk(source_folder):\n",
    "    for i,file in enumerate(files):\n",
    "        r,m = load_raster(os.path.join(subdir, file), False)\n",
    "        name = file.split('.')[0].split('bw_')[-1]\n",
    "        rivers[name] = r\n",
    "\n",
    "# Load input paths\n",
    "for i,dir_p in enumerate(dir_paths):\n",
    "    for subdir, dirs,files in os.walk(dir_p):\n",
    "        if subdir != dir_p and not subdir.endswith('masked') and not subdir.endswith('.ipynb_checkpoints'): \n",
    "            all_dir_paths[data_paths[i]].append(subdir)\n",
    "        elif subdir.endswith('masked'):\n",
    "            all_dir_paths['masked'].append(subdir)\n",
    "\n",
    "# Load input data\n",
    "for k,v in all_dir_paths.items():\n",
    "    if filter_river != None:\n",
    "        v = [v[i] for i in filter_river]\n",
    "    \n",
    "    if k != 'discharge' and k != 'slope':\n",
    "        if k == 'lst' or k == 'masked':\n",
    "            list_rgb = [True]*len(v)\n",
    "        else:\n",
    "            list_rgb = [False]*len(v)\n",
    "            \n",
    "        data, times = load_data(v,W,list_rgb)\n",
    "        if k!='masked':\n",
    "            labels = []\n",
    "            for ki,value in data.items():\n",
    "                labels+=[ki.split('/')[-1]]*len(value)\n",
    "        \n",
    "        filtered = [arr for arr in data.values() if arr.size > 0]\n",
    "\n",
    "        total_data[k] = np.concatenate(filtered, axis=0)\n",
    "        total_times[k] = times\n",
    "        print(k,':' ,total_data[k].shape)\n",
    "\n",
    "    elif k == 'discharge' or k == 'slope':\n",
    "        total = []\n",
    "        for p in v:\n",
    "            for file in os.listdir(p):\n",
    "                file_path = os.path.join(p, file)\n",
    "                r,m = load_raster(file_path, False)\n",
    "                var = resize_image(r, W,W)\n",
    "                img_river = labels.count(p.split(\"/\")[-1])\n",
    "                var_input = np.tile(var, (img_river, 1, 1))\n",
    "                total.append(var_input)\n",
    "        \n",
    "        total_data[k] = np.concatenate(total, axis=0)\n",
    "        print(k,':' ,total_data[k].shape)\n",
    "\n",
    "# Hot encoding\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "river_encoded = encoder.fit_transform(np.array(labels).reshape(-1, 1))\n",
    "data_targets = total_data['wt']\n",
    "results = {'MAE':0,'MSE':0,'RMSE':0,'R²':0,'MAPE (%)':0,'MSE sample-wise':0}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Y2TXyInRBmC"
   },
   "source": [
    "## Do experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = 256\n",
    "filter_river = None#[3,11,12]\n",
    "inputs = ['lst','ndvi','discharge', 'slope']#['ndvi','discharge', 'slope']\n",
    "conditioned = False\n",
    "batch_size = 16\n",
    "epochs = 10\n",
    "model_name = \"img_wise_CNN_improved\" #img_wise_CNN, UNet, transfer_learning_VGG16, CNN, img_2_img\n",
    "stratified = False\n",
    "physics_guided = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(test_target, test_prediction, rivers, labels, test_index):\n",
    "    mean_results = {k:[] for k in results.keys()}\n",
    "    # Loop through each sample and compute the MSE for that sample\n",
    "    for i in range(test_target.shape[0]):\n",
    "        # Flatten the true and predicted values for this sample\n",
    "        riv = rivers[labels[test_index[i]]].flatten()\n",
    "        y_true_flatten = test_target[i].flatten()\n",
    "        y_true_mask = y_true_flatten[riv != 0]\n",
    "        y_pred_flatten = test_prediction[i].flatten()\n",
    "        y_pred_mask = y_pred_flatten[riv != 0]\n",
    "        # Calculate metrics\n",
    "        res = evaluate_model(y_true_mask, y_pred_mask)\n",
    "        for k,v in res.items():\n",
    "            mean_results[k].append(v)\n",
    "    for key in mean_results:\n",
    "        mean_results[key] = np.mean(mean_results[key])\n",
    "    return mean_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose inputs\n",
    "inputs_d = [total_data[inp] for inp in inputs]\n",
    "# List to store the processed additional images\n",
    "expanded_images = []\n",
    "# Expand dimensions for single-channel images, leave multi-channel images as they are\n",
    "for img in inputs_d:\n",
    "    if img.ndim == 3:  # Case where image is (n, 256, 256) (single-channel)\n",
    "        expanded_images.append(np.expand_dims(img, axis=-1))  # Expand to add an extra channel\n",
    "    elif img.ndim == 4:  # Case where image already has multiple channels (n, 256, 256, c)\n",
    "        expanded_images.append(img)  # Leave the image as it is\n",
    "# Concatenate all images along the last axis (channels)\n",
    "combined_input = np.concatenate(expanded_images, axis=-1)\n",
    "# The final combined input is stored in input_data\n",
    "input_data = combined_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 88 imágenes, (88, 256, 256, 6)\n",
      "Val: 29 imágenes, (29, 256, 256, 6)\n",
      "Test: 30 imágenes, (30, 256, 256, 6)\n",
      "(88, 256, 256) (29, 256, 256) (30, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "time_split = True\n",
    "if time_split:\n",
    "    train_ratio = 0.6\n",
    "    val_ratio = 0.2\n",
    "    test_ratio = 0.2\n",
    "    \n",
    "    # Calcular el tamaño de cada conjunto\n",
    "    total_images = len(input_data)\n",
    "    train_size = int(total_images * train_ratio)\n",
    "    val_size = int(total_images * val_ratio)\n",
    "    indices = np.arange(total_images)\n",
    "    \n",
    "    train_index = indices[:train_size]                       # Primeros índices para entrenamiento\n",
    "    validation_index = indices[train_size:train_size + val_size]    # Siguientes índices para validación\n",
    "    test_index = indices[train_size + val_size:]             # Últimos índices para prueba\n",
    "   \n",
    "elif stratified:\n",
    "    train_index, validation_index, test_index = split_data_stratified(input_data, data_targets, labels)\n",
    "else:\n",
    "    train_index, validation_index, test_index = split_data(input_data, data_targets)\n",
    "        \n",
    "validation_input = input_data[validation_index, :] / 255.0  # Normalize inputs\n",
    "validation_target = data_targets[validation_index, :]\n",
    "validation_rivers = river_encoded[validation_index, :]\n",
    "test_input = input_data[test_index, :] / 255.0  # Normalize inputs\n",
    "test_target = data_targets[test_index, :]\n",
    "test_rivers = river_encoded[test_index, :]\n",
    "train_input = input_data[train_index, :] / 255.0  # Normalize inputs\n",
    "train_target = data_targets[train_index, :]\n",
    "train_rivers = river_encoded[train_index, :]\n",
    "print(f\"Train: {len(train_input)} imágenes, {train_input.shape}\")\n",
    "print(f\"Val: {len(validation_input)} imágenes, {validation_input.shape}\")\n",
    "print(f\"Test: {len(test_input)} imágenes, {test_input.shape}\")\n",
    "print(train_target.shape, validation_target.shape, test_target.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select inputs and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(train_input.shape) == 3:\n",
    "    input_shape = train_input.shape[1:]+(1,)\n",
    "else:\n",
    "    input_shape = train_input.shape[1:]\n",
    "\n",
    "\n",
    "# Adapt input to condition\n",
    "if conditioned:\n",
    "    input_args = (input_shape, river_encoded.shape[1])\n",
    "    model_input = (train_input, train_rivers)\n",
    "    val_model_input = [validation_input, validation_rivers]\n",
    "    test_model_input = [test_input, test_rivers]\n",
    "else:\n",
    "    input_args = input_shape\n",
    "    model_input = train_input\n",
    "    val_model_input = validation_input\n",
    "    test_model_input = test_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models, regularizers\n",
    "\n",
    "def build_simplified_cnn_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # Capa 1: Convolucional + BatchNormalization + ReLU + Max Pooling + Dropout\n",
    "    model.add(layers.Conv2D(16, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.0005), input_shape=input_shape))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    # Capa 2: Convolucional + BatchNormalization + ReLU + Max Pooling + Dropout\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    # Capa de aplanamiento\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    # Capa densa + BatchNormalization + Dropout\n",
    "    model.add(layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dropout(0.4))\n",
    "\n",
    "    # Capa de salida con activación lineal (para predicciones de temperatura)\n",
    "    model.add(layers.Dense(256 * 256, activation='linear'))\n",
    "\n",
    "    # Reshape de la salida a la forma (256, 256)\n",
    "    model.add(layers.Reshape((256, 256)))\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruth.parajo/miniconda3/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Start model\n",
    "start_time = time.time()\n",
    "if model_name == \"img_wise_CNN_improved\":\n",
    "    if conditioned:\n",
    "        model = build_simplified_cnn_model_label(input_args[0], input_args[1])\n",
    "    else:\n",
    "        model = build_simplified_cnn_model(input_args)\n",
    "elif model_name == 'CNN':\n",
    "    model = build_cnn_model(input_args)\n",
    "elif model_name == 'img_2_img':\n",
    "    model = build_img_2_img_model(input_args)\n",
    "elif model_name == 'UNet':\n",
    "    model = build_unet(input_args)\n",
    "elif model_name == 'transfer_learning_VGG16':\n",
    "    train_input = train_input[:, :, :, :3]\n",
    "    model = build_transfer_model((W, W, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment with model=img_wise_CNN_improved, batch_size=16, epochs=10\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1730384664.295927 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.297928 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.299789 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.301025 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.302298 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.303947 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.306160 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.307828 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.309497 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.311684 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.313404 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.316476 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.318634 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.320435 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.322233 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.323787 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.325613 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.328219 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.330819 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.334156 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.338513 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.342100 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.346213 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.348682 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.390141 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.391174 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.392224 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.393268 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.394352 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.395690 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.397196 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.398711 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.399829 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.402128 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.402985 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.404130 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.405001 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.406743 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.408053 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.409113 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.410183 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.411249 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.412972 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.414142 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.416457 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.418046 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.419607 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.483923 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.484893 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.486297 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.487535 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.489168 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.490344 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.492064 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.493783 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.496230 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.501372 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.502826 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.504351 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.506507 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.508985 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.511460 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.513925 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.516382 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.519919 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.523719 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.525123 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.526868 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.542221 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.556807 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.558450 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.561057 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.563034 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.566044 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.568071 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.571259 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.574576 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.577576 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.583129 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.585226 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.587153 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.589477 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.592441 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.595617 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.598789 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.601971 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.604987 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.609389 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.614046 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.618478 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730384664.621842 3347632 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "Epoch 3/10\n",
      "Epoch 4/10\n",
      "Epoch 5/10\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-31 15:24:30.527899: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "Epoch 8/10\n",
      "Epoch 9/10\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step\n",
      "\n",
      "Computing result metrics...\n",
      "Experiment img_wise_CNN_improved with batch_size=16 and epochs=10 completed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Running experiment with model={model_name}, batch_size={batch_size}, epochs={epochs}\")\n",
    "\n",
    "# Train the model\n",
    "if not physics_guided:\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "    history = model.fit(model_input, train_target, batch_size=batch_size, epochs=epochs, validation_data=(val_model_input, validation_target))\n",
    "else:\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((*model_input, train_target) if isinstance(model_input, tuple) else (model_input, train_target))\n",
    "\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        for batch in dataset:\n",
    "            # Handle batch based on whether model_input is a tuple or a single dataset\n",
    "            if isinstance(model_input, tuple):\n",
    "                model_input_batch = batch[:-1]  # All except the last element (target_batch)\n",
    "                target_batch = batch[-1]        # Last element is target_batch\n",
    "            else:\n",
    "                model_input_batch, target_batch = batch  # Direct unpacking for single dataset\n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "                y_pred = model([*model_input_batch], training=True) if isinstance(model_input_batch, tuple) else model(model_input_batch, training=True)\n",
    "                loss = conservation_energy_loss(target_batch, y_pred, model_input_batch, alpha=0.5, beta=0.5)\n",
    "            gradients = tape.gradient(loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "\n",
    "# Evaluate results\n",
    "#validation_prediction = model.predict(val_model_input)\n",
    "test_prediction = model.predict(test_model_input)\n",
    "\n",
    "print('\\nComputing result metrics...')\n",
    "mean_results = get_results(test_target, test_prediction, rivers, labels, test_index)\n",
    "\n",
    "# Get experiment data\n",
    "end_time = time.time()\n",
    "duration = round(end_time - start_time, 2)\n",
    "current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "\n",
    "\n",
    "# Save model results\n",
    "laabeel = 'label' if conditioned else 'no label'\n",
    "var_inputs = '' if inputs == None else ', '.join(inputs)\n",
    "variables = ', '.join([var_inputs, laabeel])\n",
    "details = {'RMSE':mean_results['RMSE'],'Variables':variables,'Input': f'{len(np.unique(labels))} rivers', 'Output': 'wt', \\\n",
    "           'Resolution': W, 'nº samples': len(data_targets), 'Batch size': batch_size, 'Epochs': epochs, 'Date':current_date, \\\n",
    "           'Time':current_time, 'Duration': duration, 'Loss': 'Physics-guided'}\n",
    "\n",
    "file_path = f\"../results/{model_name}_results.xlsx\"\n",
    "save_excel(file_path, details, excel = 'Results')\n",
    "\n",
    "mean_results['Model'] = model_name\n",
    "file_path = f\"../results/all_results.xlsx\"\n",
    "save_excel(file_path, mean_results, excel = 'Results')\n",
    "\n",
    "print(f\"Experiment {model_name} with batch_size={batch_size} and epochs={epochs} completed.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Variables</th>\n",
       "      <th>Input</th>\n",
       "      <th>Output</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>nº samples</th>\n",
       "      <th>Batch size</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.952328</td>\n",
       "      <td>lst, ndvi, discharge, slope, no label, stratified</td>\n",
       "      <td>13 rivers</td>\n",
       "      <td>wt</td>\n",
       "      <td>256</td>\n",
       "      <td>147</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>2024-10-31</td>\n",
       "      <td>14:56:12</td>\n",
       "      <td>81.14</td>\n",
       "      <td>Physics-guided</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       RMSE                                          Variables      Input  \\\n",
       "0  3.952328  lst, ndvi, discharge, slope, no label, stratified  13 rivers   \n",
       "\n",
       "  Output  Resolution  nº samples  Batch size  Epochs        Date      Time  \\\n",
       "0     wt         256         147           8      10  2024-10-31  14:56:12   \n",
       "\n",
       "   Duration            Loss  \n",
       "0     81.14  Physics-guided  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#model_name = 'img_wise_CNN'\n",
    "pd.read_excel(f'../results/{model_name}_results.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.596295118331909, 'lst, ndvi, no label', '13 rivers', 'wt', 256, 147, 16, 10, '2024-10-30', '16:53:12', 64.91, 'Physics-guided']\n",
      "[3.606398582458496, 'lst, slope, discharge, no label', '13 rivers', 'wt', 256, 147, 16, 10, '2024-10-30', '17:01:12', 61.02, 'Physics-guided']\n",
      "[3.610826969146729, 'lst, slope, discharge, ndvi, no label', '13 rivers', 'wt', 256, 147, 16, 10, '2024-10-30', '17:09:33', 65.83, 'Physics-guided']\n",
      "[3.601340293884277, 'lst, no label', '13 rivers', 'wt', 256, 147, 16, 10, '2024-10-30', '17:17:52', 64.03, 'Physics-guided']\n",
      "[3.674090147018433, 'lst, ndvi, no label', '13 rivers', 'wt', 256, 147, 16, 10, '2024-10-31', '09:20:38', 65.53, 'Physics-guided']\n",
      "[3.712287664413452, 'lst, ndvi, label', '13 rivers', 'wt', 256, 147, 16, 10, '2024-10-31', '09:21:40', 62.04, 'Physics-guided']\n",
      "[3.746084451675415, 'lst, ndvi, no label', '13 rivers', 'wt', 256, 147, 16, 10, '2024-10-31', '09:36:47', 69.57, 'RMSE']\n",
      "[3.768811941146851, 'lst, ndvi, label', '13 rivers', 'wt', 256, 147, 16, 10, '2024-10-31', '09:37:54', 66.11, 'RMSE']\n",
      "[3.704513311386108, 'lst, slope, discharge, no label', '13 rivers', 'wt', 256, 147, 16, 10, '2024-10-31', '09:51:21', 67.03, 'RMSE']\n",
      "[3.728540182113647, 'lst, slope, discharge, label', '13 rivers', 'wt', 256, 147, 16, 10, '2024-10-31', '09:52:28', 65.96, 'RMSE']\n",
      "[3.729133367538452, 'lst, slope, discharge, ndvi, no label', '13 rivers', 'wt', 256, 147, 16, 10, '2024-10-31', '10:06:13', 69.34, 'RMSE']\n",
      "[3.706898212432861, 'lst, slope, discharge, ndvi, label', '13 rivers', 'wt', 256, 147, 16, 10, '2024-10-31', '10:07:19', 65.82, 'RMSE']\n",
      "[3.796441078186035, 'lst, no label', '13 rivers', 'wt', 256, 147, 16, 10, '2024-10-31', '10:21:13', 66.12, 'RMSE']\n",
      "[3.724769115447998, 'lst, label', '13 rivers', 'wt', 256, 147, 16, 10, '2024-10-31', '10:22:18', 65.2, 'RMSE']\n"
     ]
    }
   ],
   "source": [
    "ds = pd.read_excel(f'../results/img_wise_CNN_results.xlsx')\n",
    "for i,r in ds.iterrows():\n",
    "    if r['Epochs']==10 and r['Batch size']==16:\n",
    "        print(list(r))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 728,
     "status": "ok",
     "timestamp": 1728047630422,
     "user": {
      "displayName": "Ruth Parajó Ferrer",
      "userId": "07031545869212809064"
     },
     "user_tz": -120
    },
    "id": "8lInUBSuqaJL",
    "outputId": "6da1d732-2f2a-4228-d35f-de06e5ff7803",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "executionInfo": {
     "elapsed": 575,
     "status": "ok",
     "timestamp": 1728046187777,
     "user": {
      "displayName": "Ruth Parajó Ferrer",
      "userId": "07031545869212809064"
     },
     "user_tz": -120
    },
    "id": "EajYGsQBjG2G",
    "outputId": "1b005f05-2bee-4259-af17-0382a232a40c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,5))\n",
    "#plt.clf\n",
    "plt.plot(history.history['loss'], label='train loss')\n",
    "plt.plot(history.history['val_loss'], label='validation loss')\n",
    "plt.title('Simpler CNN MSE Loss during training --- lst+ndvi with wt target')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('../plots/cnn.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "executionInfo": {
     "elapsed": 436,
     "status": "ok",
     "timestamp": 1728043130132,
     "user": {
      "displayName": "Ruth Parajó Ferrer",
      "userId": "07031545869212809064"
     },
     "user_tz": -120
    },
    "id": "0EYej4lojG2G",
    "outputId": "ea68cef6-398f-422a-8401-e6c02609ee06"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['mae'], label='Training MAE')\n",
    "plt.plot(history.history['val_mae'], label='Validation MAE')\n",
    "plt.title('MAE during training')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uv2k19g5jG2H"
   },
   "source": [
    "#### Validate and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ow08ZqWsjG2J"
   },
   "source": [
    "Image wise metrics results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RbJ77fRFjG2J"
   },
   "source": [
    "See what are the areas with more prediction error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 4054,
     "status": "ok",
     "timestamp": 1728043150628,
     "user": {
      "displayName": "Ruth Parajó Ferrer",
      "userId": "07031545869212809064"
     },
     "user_tz": -120
    },
    "id": "SqvaSLQhjtR6",
    "outputId": "4d3a25c8-67ba-434a-ef58-cf84d17905af",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if len(validation_prediction.shape) == 4:\n",
    "  validation_prediction=np.squeeze(validation_prediction, axis=3)\n",
    "\n",
    "diff = validation_prediction - validation_target\n",
    "for i in range(diff.shape[0]):\n",
    "  sns.heatmap(diff[i], cmap='coolwarm')\n",
    "  plt.title('Prediction Error Heatmap')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "42nOYweqjG2K"
   },
   "source": [
    "Dispersion graph and histogram of prediction errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_target_flat = validation_target.reshape(-1)\n",
    "validation_prediction_flat = validation_prediction.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 927
    },
    "executionInfo": {
     "elapsed": 831,
     "status": "ok",
     "timestamp": 1728043151456,
     "user": {
      "displayName": "Ruth Parajó Ferrer",
      "userId": "07031545869212809064"
     },
     "user_tz": -120
    },
    "id": "AtO-_TdpjG2K",
    "outputId": "c077eb5e-f4e6-4156-f9f2-55468aa1b0fd"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Supongamos que y_true son tus valores reales y y_pred son tus predicciones\n",
    "y_true = validation_target_flat # Valores reales\n",
    "y_pred = validation_prediction_flat  # Predicciones del modelo\n",
    "\n",
    "# Visualización\n",
    "plt.scatter(y_true, y_pred)\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions')\n",
    "plt.plot([min(y_true), max(y_true)], [min(y_true), max(y_true)], 'r--')\n",
    "plt.title('True Values vs Predictions')\n",
    "plt.show()\n",
    "\n",
    "# Histograma de errores\n",
    "errors = y_pred - y_true\n",
    "plt.hist(errors, bins=30)\n",
    "plt.xlabel('Error')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Prediction Errors')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMOhs4aAZ7i01xBD4Eg2RuL",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
